{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qEQqrjozIFOO"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O \n",
    "import os\n",
    "# data = pd.read_csv(\"dataset/mbti_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-3bIs1iwXVm",
    "outputId": "ded57d94-cbc4-438b-ea76-269344bbff7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxCh-eppw4H-",
    "outputId": "0b44a8c4-5fe3-4455-ed12-e4c1ecc27e92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/personality\n"
     ]
    }
   ],
   "source": [
    "%cd drive/My\\ Drive/personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6g1njtpxxxXT"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"datasets/mbti_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aGuABPASssNz"
   },
   "outputs": [],
   "source": [
    "per_types = ['ENFJ','ENFP','ENTJ','ENTP','ESFJ','ESFP','ESTJ','ESTP','INFJ','INFP','INTJ','INTP','ISFJ','ISFP','ISTJ','ISTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "W8ZNYhAsJGvu",
    "outputId": "26c95aa7-62f0-44bc-bbcd-7b494f0c721c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'18/37 @.@|||Science  is not perfect. No scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'No, I can't draw on my own nails (haha). Thos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'I tend to build up a collection of things on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>I'm not sure, that's a good question. The dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=w8-egj0y8Qs||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'One time my parents were fighting over my dad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>'https://www.youtube.com/watch?v=PLAaiKvHvZs||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Joe santagato - ENTP|||ENFJ or  ENTP?   I'm n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Fair enough, if that's how you want to look a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Basically this...  https://youtu.be/1pH5c1Jkh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Your comment screams INTJ, bro. Especially th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                              posts\n",
       "0   INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1   ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2   INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3   INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4   ENTJ  'You're fired.|||That's another silly misconce...\n",
       "5   INTJ  '18/37 @.@|||Science  is not perfect. No scien...\n",
       "6   INFJ  'No, I can't draw on my own nails (haha). Thos...\n",
       "7   INTJ  'I tend to build up a collection of things on ...\n",
       "8   INFJ  I'm not sure, that's a good question. The dist...\n",
       "9   INTP  'https://www.youtube.com/watch?v=w8-egj0y8Qs||...\n",
       "10  INFJ  'One time my parents were fighting over my dad...\n",
       "11  ENFJ  'https://www.youtube.com/watch?v=PLAaiKvHvZs||...\n",
       "12  INFJ  'Joe santagato - ENTP|||ENFJ or  ENTP?   I'm n...\n",
       "13  INTJ  'Fair enough, if that's how you want to look a...\n",
       "14  INTP  'Basically this...  https://youtu.be/1pH5c1Jkh...\n",
       "15  INTP  'Your comment screams INTJ, bro. Especially th..."
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IPAbwV_wMULM"
   },
   "outputs": [],
   "source": [
    "types = np.unique(data.type.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AxO7gtOsNFqg"
   },
   "outputs": [],
   "source": [
    "def get_type_index(string):\n",
    "    return list(types).index(string)\n",
    "data['type_index'] = data['type'].apply(get_type_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "1kM3aVjQNJsT",
    "outputId": "3ee2fd9d-dd06-48e4-c3bf-ca5367c9843f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait... I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can. Don't worry, people will always be around to...|||Yo entp ladies... if you're into a complimentary personality,well, hey.|||... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as...|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own... like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm... yep.|||Ahh... old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too...|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.'\""
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.posts.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-wMgiWagNNFZ"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    regex = re.compile('[%s]' % re.escape('|'))\n",
    "    text = regex.sub(\" \", text)\n",
    "    words = str(text).split()\n",
    "    words = [i.lower() + \" \" for i in words]\n",
    "    words = [i for i in words if not \"http\" in i]\n",
    "    words = \" \".join(words)\n",
    "    words = words.translate(words.maketrans('', '', string.punctuation))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GH6wx4O9NQzz"
   },
   "outputs": [],
   "source": [
    "data['cleaned_text'] = data['posts'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "4QcsPmmZNSsg",
    "outputId": "03f8b16f-7da4-4fb9-e7e9-55d8c1bcc70a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'enfp  and  intj  moments  sportscenter  not  top  ten  plays  pranks  what  has  been  the  most  lifechanging  experience  in  your  life  on  repeat  for  most  of  today  may  the  perc  experience  immerse  you  the  last  thing  my  infj  friend  posted  on  his  facebook  before  committing  suicide  the  next  day  rest  in  peace  hello  enfj7  sorry  to  hear  of  your  distress  its  only  natural  for  a  relationship  to  not  be  perfection  all  the  time  in  every  moment  of  existence  try  to  figure  the  hard  times  as  times  of  growth  as  84389  84390    welcome  and  stuff  game  set  match  prozac  wellbrutin  at  least  thirty  minutes  of  moving  your  legs  and  i  dont  mean  moving  them  while  sitting  in  your  same  desk  chair  weed  in  moderation  maybe  try  edibles  as  a  healthier  alternative  basically  come  up  with  three  items  youve  determined  that  each  type  or  whichever  types  you  want  to  do  would  more  than  likely  use  given  each  types  cognitive  functions  and  whatnot  when  left  by  all  things  in  moderation  sims  is  indeed  a  video  game  and  a  good  one  at  that  note  a  good  one  at  that  is  somewhat  subjective  in  that  i  am  not  completely  promoting  the  death  of  any  given  sim  dear  enfp  what  were  your  favorite  video  games  growing  up  and  what  are  your  now  current  favorite  video  games  cool  it  appears  to  be  too  late  sad  theres  someone  out  there  for  everyone  wait  i  thought  confidence  was  a  good  thing  i  just  cherish  the  time  of  solitude  bc  i  revel  within  my  inner  world  more  whereas  most  other  time  id  be  workin  just  enjoy  the  me  time  while  you  can  dont  worry  people  will  always  be  around  to  yo  entp  ladies  if  youre  into  a  complimentary  personalitywell  hey    when  your  main  social  outlet  is  xbox  live  conversations  and  even  then  you  verbally  fatigue  quickly  i  really  dig  the  part  from  146  to  250  banned  because  this  thread  requires  it  of  me  get  high  in  backyard  roast  and  eat  marshmellows  in  backyard  while  conversing  over  something  intellectual  followed  by  massages  and  kisses  banned  for  too  many  bs  in  that  sentence  how  could  you  think  of  the  b  banned  for  watching  movies  in  the  corner  with  the  dunces  banned  because  health  class  clearly  taught  you  nothing  about  peer  pressure  banned  for  a  whole  host  of  reasons  1  two  baby  deer  on  left  and  right  munching  on  a  beetle  in  the  middle  2  using  their  own  blood  two  cavemen  diary  todays  latest  happenings  on  their  designated  cave  diary  wall  3  i  see  it  as  a  pokemon  world  an  infj  society  everyone  becomes  an  optimist  49142  not  all  artists  are  artists  because  they  draw  its  the  idea  that  counts  in  forming  something  of  your  own  like  a  signature  welcome  to  the  robot  ranks  person  who  downed  my  selfesteem  cuz  im  not  an  avid  signature  artist  like  herself  proud  banned  for  taking  all  the  room  under  my  bed  ya  gotta  learn  to  share  with  the  roaches  banned  for  being  too  much  of  a  thundering  grumbling  kind  of  storm  yep  ahh  old  high  school  music  i  havent  heard  in  ages  i  failed  a  public  speaking  class  a  few  years  ago  and  ive  sort  of  learned  what  i  could  do  better  were  i  to  be  in  that  position  again  a  big  part  of  my  failure  was  just  overloading  myself  with  too  i  like  this  persons  mentality  hes  a  confirmed  intj  by  the  way  move  to  the  denver  area  and  start  a  new  life  for  myself '"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cleaned_text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YvsL6L9yNV3r"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data)\n",
    "train, val = train_test_split(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arU9jhwp3MxF",
    "outputId": "35915b2b-4231-4854-8f60-dbe0bda1af6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4879, 4)\n",
      "(1627, 4)\n",
      "(2169, 4)\n"
     ]
    }
   ],
   "source": [
    "print (train.shape)\n",
    "print (val.shape)\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ypaVavSNbP-",
    "outputId": "0d580091-7133-4e4b-b3cc-154a97e6d6d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vejsz3HbNjNa"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ON3v_358NvZL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Flatten, Dropout, Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "def create_model():\n",
    "    op = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 256, input_length=maxlen-1))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(200, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(16, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=op, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PG4nOZ9XPKor"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 10000\n",
    "trunc_type = \"post\"\n",
    "pad_type = \"post\"\n",
    "oov_tok = \"<OOV>\"\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(data.cleaned_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrWQfyY_NhJw"
   },
   "outputs": [],
   "source": [
    "maxlen = 1500\n",
    "train_sequences = tokenizer.texts_to_sequences(train.cleaned_text.values)\n",
    "train_padded = pad_sequences(train_sequences, maxlen = maxlen, truncating = trunc_type, padding = pad_type)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val.cleaned_text.values)\n",
    "val_padded = pad_sequences(val_sequences, maxlen = maxlen, truncating = trunc_type, padding = pad_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RskUoy03U_6",
    "outputId": "7fb62254-8391-47a4-bde5-3dd1f73eabc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4879, 1500)\n",
      "(1627, 1500)\n"
     ]
    }
   ],
   "source": [
    "print (train_padded.shape)\n",
    "print (val_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vI170zWhN2LB",
    "outputId": "6e0e24a0-8f32-46bf-bb7e-0e2261504e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1499, 256)         2560000   \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 1499, 256)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1499, 400)         731200    \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 1499, 400)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 40)                67360     \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2624      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 3,362,224\n",
      "Trainable params: 3,362,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "use_tpu = False\n",
    "if use_tpu:\n",
    "    # Create distribution strategy\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "    # Create model\n",
    "    with strategy.scope():\n",
    "        model = create_model()\n",
    "else:\n",
    "    model = create_model()\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DO2PIRQ4VKIl"
   },
   "outputs": [],
   "source": [
    "one_hot_labels = tf.keras.utils.to_categorical(train.type_index.values, num_classes=16)\n",
    "val_labels= tf.keras.utils.to_categorical(val.type_index.values, num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRbHqytY3Bey",
    "outputId": "326fe7bb-8ae2-466c-ecae-b30e99984bb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWFpvc4GN6ac",
    "outputId": "4e21cd78-7341-46c0-fe47-78364867b2c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/153 [..............................] - ETA: 2:51 - loss: 2.7706 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 2.2603s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 2.2603s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - ETA: 0s - loss: 2.7562 - accuracy: 0.1209WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_test_batch_end` time: 0.7025s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_test_batch_end` time: 0.7025s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "153/153 [==============================] - 377s 2s/step - loss: 2.7562 - accuracy: 0.1209 - val_loss: 2.7320 - val_accuracy: 0.1309\n",
      "Epoch 2/20\n",
      "153/153 [==============================] - 378s 2s/step - loss: 2.7045 - accuracy: 0.1301 - val_loss: 2.6568 - val_accuracy: 0.1266\n",
      "Epoch 3/20\n",
      "153/153 [==============================] - 382s 2s/step - loss: 2.6159 - accuracy: 0.1289 - val_loss: 2.5366 - val_accuracy: 0.1266\n",
      "Epoch 4/20\n",
      "153/153 [==============================] - 383s 3s/step - loss: 2.5340 - accuracy: 0.1287 - val_loss: 2.4307 - val_accuracy: 0.1266\n",
      "Epoch 5/20\n",
      "153/153 [==============================] - 384s 3s/step - loss: 2.4562 - accuracy: 0.1685 - val_loss: 2.3695 - val_accuracy: 0.2090\n",
      "Epoch 6/20\n",
      "153/153 [==============================] - 387s 3s/step - loss: 2.4191 - accuracy: 0.1781 - val_loss: 2.3453 - val_accuracy: 0.2090\n",
      "Epoch 7/20\n",
      "153/153 [==============================] - 386s 3s/step - loss: 2.3962 - accuracy: 0.1841 - val_loss: 2.3307 - val_accuracy: 0.2090\n",
      "Epoch 8/20\n",
      "153/153 [==============================] - 386s 3s/step - loss: 2.3919 - accuracy: 0.1836 - val_loss: 2.3209 - val_accuracy: 0.2090\n",
      "Epoch 9/20\n",
      "153/153 [==============================] - 385s 3s/step - loss: 2.3825 - accuracy: 0.1802 - val_loss: 2.3127 - val_accuracy: 0.2090\n",
      "Epoch 10/20\n",
      "153/153 [==============================] - 388s 3s/step - loss: 2.3717 - accuracy: 0.1910 - val_loss: 2.3063 - val_accuracy: 0.2090\n",
      "Epoch 11/20\n",
      "153/153 [==============================] - 388s 3s/step - loss: 2.3660 - accuracy: 0.1830 - val_loss: 2.3019 - val_accuracy: 0.2090\n",
      "Epoch 12/20\n",
      "153/153 [==============================] - 389s 3s/step - loss: 2.3638 - accuracy: 0.1843 - val_loss: 2.2973 - val_accuracy: 0.2090\n",
      "Epoch 13/20\n",
      "153/153 [==============================] - 388s 3s/step - loss: 2.3551 - accuracy: 0.1859 - val_loss: 2.2935 - val_accuracy: 0.2090\n",
      "Epoch 14/20\n",
      "153/153 [==============================] - 389s 3s/step - loss: 2.3582 - accuracy: 0.1927 - val_loss: 2.2903 - val_accuracy: 0.2090\n",
      "Epoch 15/20\n",
      "153/153 [==============================] - 389s 3s/step - loss: 2.3490 - accuracy: 0.1898 - val_loss: 2.2874 - val_accuracy: 0.2090\n",
      "Epoch 16/20\n",
      "153/153 [==============================] - 388s 3s/step - loss: 2.3518 - accuracy: 0.1904 - val_loss: 2.2848 - val_accuracy: 0.2090\n",
      "Epoch 17/20\n",
      "153/153 [==============================] - 389s 3s/step - loss: 2.3518 - accuracy: 0.1810 - val_loss: 2.2834 - val_accuracy: 0.2090\n",
      "Epoch 18/20\n",
      "153/153 [==============================] - 388s 3s/step - loss: 2.3434 - accuracy: 0.1908 - val_loss: 2.2808 - val_accuracy: 0.2090\n",
      "Epoch 19/20\n",
      "153/153 [==============================] - 388s 3s/step - loss: 2.3434 - accuracy: 0.1871 - val_loss: 2.2790 - val_accuracy: 0.2090\n",
      "Epoch 20/20\n",
      "153/153 [==============================] - 389s 3s/step - loss: 2.3383 - accuracy: 0.1896 - val_loss: 2.2773 - val_accuracy: 0.2090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7499446a0>"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_padded, one_hot_labels, epochs =20, verbose = 1, \n",
    "          validation_data = (val_padded, val_labels),  callbacks = [tf.keras.callbacks.EarlyStopping(patience = 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_w8GLlGU--7"
   },
   "outputs": [],
   "source": [
    "model.save(\"models/personality_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "ZE73jKM-g-0T",
    "outputId": "b1efcbe2-c650-41cf-df58-0e35b3f5b8b0"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-5272130c3e8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/bert_base_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Check its architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.models' has no attribute 'load_weights'"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('models/personality_model.h5')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-53QKaxmqUZ0"
   },
   "outputs": [],
   "source": [
    "test_labels= tf.keras.utils.to_categorical(test.type_index.values, num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6UzBhcyutni"
   },
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test.cleaned_text.values)\n",
    "test_padded = pad_sequences(test_sequences, maxlen = 1500, truncating = trunc_type, padding = pad_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nMRmiIRFrCt4",
    "outputId": "0e148254-2695-4323-d9ec-aa43e01259dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n",
      "68/68 [==============================] - 203s 3s/step - loss: 2.2858 - accuracy: 0.2112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2857666015625, 0.21115721762180328]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(np.array(test_padded), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Melw7KJYusgS",
    "outputId": "e0a875cf-7001-48cd-b4af-785dffdfad83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n",
      "[[0.01755055 0.0746889  0.03881089 ... 0.02421712 0.03078783 0.04636303]\n",
      " [0.01594081 0.07214715 0.03871734 ... 0.02321349 0.02850211 0.04422106]\n",
      " [0.01591561 0.07223146 0.03868169 ... 0.02324132 0.02850406 0.04427687]\n",
      " ...\n",
      " [0.01594858 0.07234409 0.03864701 ... 0.02324031 0.02856634 0.0442911 ]\n",
      " [0.01590267 0.07214415 0.03858009 ... 0.02319117 0.02843972 0.04423463]\n",
      " [0.01759198 0.07485618 0.03879917 ... 0.02430656 0.03092699 0.04642294]]\n"
     ]
    }
   ],
   "source": [
    "print(new_model.predict(test_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sa2EnuihtrML",
    "outputId": "b881dfa1-1aa9-45e2-aa4e-f82a057e5399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[190, 6, 139, 1305, 1, 1, 916, 1, 487, 2763, 1, 1, 23, 704, 1856, 2079, 1, 1, 916, 1, 487, 2763, 1, 9953]]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks\"\n",
    "cleaned_ip = clean_text(input_text)\n",
    "list_input = []\n",
    "list_input.append(input_text)\n",
    "custom_test_sequences = tokenizer.texts_to_sequences(list_input)\n",
    "print (custom_test_sequences)\n",
    "custom_test_padded = pad_sequences(custom_test_sequences, maxlen = maxlen, truncating = trunc_type, padding = pad_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHlOuwcYxtgL",
    "outputId": "7c7246df-ba6a-4f5c-c2af-ccd8a8547bf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1500)\n"
     ]
    }
   ],
   "source": [
    "print (custom_test_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEgq62-sxXYI",
    "outputId": "0f9a0225-fb2f-4b8c-9dce-ab758e2278cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    INFP\n",
      "Name: type, dtype: object\n"
     ]
    }
   ],
   "source": [
    "type_person = np.argmax(new_model.predict(custom_test_padded))\n",
    "print (data[data[\"type_index\"]==type_person][\"type\"].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eu781MVr4_XA"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wBi902R167b",
    "outputId": "a6c5c0df-b3f0-4a9e-c2f5-9e622ec7867f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "maxlen = 1500\n",
    "\n",
    "train_input_ids = [tokenizer.encode(str(i), max_length = maxlen , pad_to_max_length = True) for i in train.cleaned_text.values]\n",
    "val_input_ids = [tokenizer.encode(str(i), max_length = maxlen , pad_to_max_length = True) for i in val.cleaned_text.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "A-u8idKg2Tsk"
   },
   "outputs": [],
   "source": [
    "def create_model(): \n",
    "    input_word_ids = tf.keras.layers.Input(shape=(maxlen,), dtype=tf.int32,\n",
    "                                           name=\"input_word_ids\")\n",
    "    bert_layer = transformers.TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    bert_outputs = bert_layer(input_word_ids)[0]\n",
    "    pred = tf.keras.layers.Dense(16, activation='softmax')(bert_outputs[:,0,:])\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_word_ids, outputs=pred)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.00001), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlkLSQ0p3CbT",
    "outputId": "c492ed33-9e79-4861-e099-976ad5be1f7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.39.75.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system grpc://10.39.75.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.39.75.10:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.39.75.10:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, 1500)]            0         \n",
      "_________________________________________________________________\n",
      "tf_bert_model (TFBertModel)  ((None, 1500, 768), (None 109482240 \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                12304     \n",
      "=================================================================\n",
      "Total params: 109,494,544\n",
      "Trainable params: 109,494,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "use_tpu = True\n",
    "if use_tpu:\n",
    "    # Create distribution strategy\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "    # Create model\n",
    "    with strategy.scope():\n",
    "        model = create_model()\n",
    "else:\n",
    "    model = create_model()\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gerAnWO33I0P",
    "outputId": "94b6a41c-8fc7-42e6-a5fc-e2ca476a097a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/305 [..............................] - ETA: 47s - loss: 3.2812 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0144s vs `on_train_batch_end` time: 0.2980s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0144s vs `on_train_batch_end` time: 0.2980s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 [==============================] - ETA: 0s - loss: 2.3365 - accuracy: 0.1939WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_test_batch_end` time: 0.0800s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_test_batch_end` time: 0.0800s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "305/305 [==============================] - 118s 387ms/step - loss: 2.3365 - accuracy: 0.1939 - val_loss: 2.2533 - val_accuracy: 0.2182\n",
      "Epoch 2/10\n",
      "305/305 [==============================] - 106s 346ms/step - loss: 1.9815 - accuracy: 0.3488 - val_loss: 1.5215 - val_accuracy: 0.5538\n",
      "Epoch 3/10\n",
      "305/305 [==============================] - 106s 347ms/step - loss: 1.3751 - accuracy: 0.5880 - val_loss: 1.2536 - val_accuracy: 0.6251\n",
      "Epoch 4/10\n",
      "305/305 [==============================] - 106s 348ms/step - loss: 1.1214 - accuracy: 0.6573 - val_loss: 1.2290 - val_accuracy: 0.6380\n",
      "Epoch 5/10\n",
      "305/305 [==============================] - 106s 348ms/step - loss: 1.0061 - accuracy: 0.6948 - val_loss: 1.1942 - val_accuracy: 0.6552\n",
      "Epoch 6/10\n",
      "305/305 [==============================] - 105s 343ms/step - loss: 0.8854 - accuracy: 0.7268 - val_loss: 1.2493 - val_accuracy: 0.6447\n",
      "Epoch 7/10\n",
      "305/305 [==============================] - 103s 339ms/step - loss: 0.7650 - accuracy: 0.7639 - val_loss: 1.2459 - val_accuracy: 0.6454\n",
      "Epoch 8/10\n",
      "305/305 [==============================] - 103s 338ms/step - loss: 0.6531 - accuracy: 0.7938 - val_loss: 1.3493 - val_accuracy: 0.6380\n",
      "Epoch 9/10\n",
      "305/305 [==============================] - 103s 338ms/step - loss: 0.5218 - accuracy: 0.8356 - val_loss: 1.4317 - val_accuracy: 0.6374\n",
      "Epoch 10/10\n",
      "305/305 [==============================] - 103s 339ms/step - loss: 0.3994 - accuracy: 0.8778 - val_loss: 1.5000 - val_accuracy: 0.6454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d4b51af98>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "model.fit(np.array(train_input_ids), one_hot_labels,validation_data = (np.array(val_input_ids), val_labels),\n",
    "          verbose = 1, epochs = 10, batch_size = batch_size,  callbacks = [tf.keras.callbacks.EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ouqqAlsL3ufr"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"models/bert_base_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qB-rPwIG_bzE",
    "outputId": "afd43879-9274-4ebb-9b59-18542b9f7c34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "test_input_ids = [tokenizer.encode(str(i), max_length = maxlen , pad_to_max_length = True) for i in test.cleaned_text.values]\n",
    "test_labels= tf.keras.utils.to_categorical(test.type_index.values, num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HgmFAWYj_73r",
    "outputId": "5c09ff3e-b97e-4fe1-84c8-2c41df2a4ea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/68 [..............................] - ETA: 3:47 - loss: 1.7032 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_test_batch_end` time: 0.1444s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_test_batch_end` time: 0.1444s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 17s 244ms/step - loss: 1.4924 - accuracy: 0.6330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4923721551895142, 0.6330106258392334]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(np.array(test_input_ids), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3Pg_3TAAvVr",
    "outputId": "8e31e449-0c6b-499e-aa84-3aa4309a098e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, 1500)]            0         \n",
      "_________________________________________________________________\n",
      "tf_bert_model (TFBertModel)  ((None, 1500, 768), (None 109482240 \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                12304     \n",
      "=================================================================\n",
      "Total params: 109,494,544\n",
      "Trainable params: 109,494,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "0JoZTKgbJejH"
   },
   "outputs": [],
   "source": [
    "def recreate_model(): \n",
    "    input_word_ids = tf.keras.layers.Input(shape=(maxlen,), dtype=tf.int32,\n",
    "                                           name=\"input_word_ids\")\n",
    "    bert_layer = transformers.TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    bert_outputs = bert_layer(input_word_ids)[0]\n",
    "    pred = tf.keras.layers.Dense(16, activation='softmax')(bert_outputs[:,0,:])\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_word_ids, outputs=pred)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.00001), metrics=['accuracy'])\n",
    "    model.load_weights(\"models/bert_base_model.h5\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EppQHdldLB7u",
    "outputId": "5c4f2e6f-e3be-4c92-a435-297adcf3c02c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "new_model = recreate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "H731zMmfLE9-"
   },
   "outputs": [],
   "source": [
    "input_text = \"enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks\"\n",
    "cleaned_ip = clean_text(input_text)\n",
    "custom_test_ids = [tokenizer.encode(str(cleaned_ip))]\n",
    "type_ind = np.argmax(new_model.predict(np.array(custom_test_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mNAEhUgyLN6b",
    "outputId": "d804429f-2779-474a-9045-afeb54122aed"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'INTJ'"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_types[type_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>traits</th>\n",
       "      <th>career</th>\n",
       "      <th>eminent personalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>[\"Systematic\",”Factual”,”Organized”,”Logical”]</td>\n",
       "      <td>,[\"Military officer”, “Lawyer”, “Judge”, “Poli...</td>\n",
       "      <td>[\"Henry Ford”, “Jeff Bezos”, “Julia Roberts”, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>[\"Warm\", \"Detailed\", \"Caring\", \"Practical\", \"F...</td>\n",
       "      <td>[\"Counselor”, “Human Resource”, “Manager”, “In...</td>\n",
       "      <td>[\"Jimmy Carter”, “Mother Teresa”, “Pope Franci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                             traits  \\\n",
       "0  ISTJ     [\"Systematic\",”Factual”,”Organized”,”Logical”]   \n",
       "1  ISFJ  [\"Warm\", \"Detailed\", \"Caring\", \"Practical\", \"F...   \n",
       "\n",
       "                                              career  \\\n",
       "0  ,[\"Military officer”, “Lawyer”, “Judge”, “Poli...   \n",
       "1  [\"Counselor”, “Human Resource”, “Manager”, “In...   \n",
       "\n",
       "                               eminent personalities  \n",
       "0  [\"Henry Ford”, “Jeff Bezos”, “Julia Roberts”, ...  \n",
       "1  [\"Jimmy Carter”, “Mother Teresa”, “Pope Franci...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"reference_data/MBTI.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = df[df[\"type\"]==\"INTP\"][\"career\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: career, dtype: object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "personality_analysis",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}